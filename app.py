
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 1) .env ã‚’èª­ã¿è¾¼ã¿ï¼ˆOPENAI_API_KEY ã‚’ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦è¨­å®šï¼‰
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
print(api_key)


def ask_llm(user_text: str, expert_type: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ ã¨ ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³é¸æŠå€¤(expert_type) ã‚’å¼•æ•°ã«å–ã‚Šã€
    LLMã®å›ç­”ï¼ˆæ–‡å­—åˆ—ï¼‰ã‚’è¿”ã™é–¢æ•°
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError(
            "OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã« OPENAI_API_KEY=sk-... ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )

    # 2) é¸æŠå€¤ã«å¿œã˜ã¦ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
    #    â€»å°‚é–€å®¶ã¯è‡ªç”±ã«è¨­è¨ˆ(A=äº‹æ¥­é–‹ç™ºã€B=Pythonå®¶åº­æ•™å¸«ï¼‰
    if expert_type == "äº‹æ¥­é–‹ç™ºã‚³ãƒ³ã‚µãƒ«ï¼ˆBizDevï¼‰":
        system_message = (
            "ã‚ãªãŸã¯å„ªç§€ãªäº‹æ¥­é–‹ç™ºã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çŠ¶æ³ã‚’å‰æã«ã€å®Ÿè¡Œå¯èƒ½ãªæ–½ç­–ã‚’ç®‡æ¡æ›¸ãã§ææ¡ˆã—ã€"
            "æœ€å¾Œã«æœ€åˆã®ä¸€æ‰‹ï¼ˆNext Actionï¼‰ã‚’1ã¤æç¤ºã—ã¦ãã ã•ã„ã€‚"
        )
    else:  # "Pythonå®¶åº­æ•™å¸«"
        system_message = (
            "ã‚ãªãŸã¯å„ªç§€ãªPythonå®¶åº­æ•™å¸«ã§ã™ã€‚"
            "åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚‹ã‚ˆã†ã«ã€çµè«–â†’ç†ç”±â†’å…·ä½“ä¾‹ã®é †ã§èª¬æ˜ã—ã€"
            "å¿…è¦ãªã‚‰çŸ­ã„ã‚³ãƒ¼ãƒ‰ä¾‹ã‚‚æç¤ºã—ã¦ãã ã•ã„ã€‚"
        )

    # 3) LLMï¼ˆLangChainï¼‰ã‚’æº–å‚™
    llm = ChatOpenAI(
        model="gpt-3.5-turbo", 
        temperature=0.3,
        api_key=api_key,
    )

    # 4) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆSystem + Humanï¼‰ã‚’æ§‹æˆ
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message),
            ("human", "{user_text}"),
        ]
    )

    chain = prompt | llm

    # 5) å®Ÿè¡Œ â†’ LangChainã®æˆ»ã‚Šã¯AIMessageãªã®ã§contentã‚’è¿”ã™
    result = chain.invoke({"user_text": user_text})
    return result.content


# ------------------------------
# Streamlit UI
# ------------------------------
st.set_page_config(page_title="Streamlit Ã— LangChain LLM App", page_icon="ğŸ¤–", layout="centered")

st.title("ğŸ¤– Streamlit Ã— LangChain LLMã‚¢ãƒ—ãƒª")
st.write(
    """
ã“ã®Webã‚¢ãƒ—ãƒªã¯ã€å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã™ã‚‹ã¨ã€LangChainçµŒç”±ã§LLMã«è³ªå•ã—ã€
å›ç­”ã‚’ç”»é¢ã«è¡¨ç¤ºã—ã¾ã™ã€‚  
å·¦ã®é¸æŠï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼‰ã§ã€LLMã®æŒ¯ã‚‹èˆã„ï¼ˆå°‚é–€å®¶ã‚¿ã‚¤ãƒ—ï¼‰ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚

**ä½¿ã„æ–¹**
1. ä¸‹ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸ã¶  
2. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•/ç›¸è«‡ã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
"""
)

expert_type = st.radio(
    "å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
    options=["äº‹æ¥­é–‹ç™ºã‚³ãƒ³ã‚µãƒ«ï¼ˆBizDevï¼‰", "Pythonå®¶åº­æ•™å¸«"],
    horizontal=True,
)

user_text = st.text_area(
    "å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆã“ã“ã«è³ªå•ã‚’å…¥åŠ›ï¼‰",
    placeholder="ä¾‹ï¼‰æ°´ç´ é–¢é€£ã®æ–°è¦äº‹æ¥­ã®æœ€åˆã®é¡§å®¢é–‹æ‹“ã®é€²ã‚æ–¹ã¯ï¼Ÿ / Pythonã®è¾æ›¸ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ ãªã©",
    height=140,
)

col1, col2 = st.columns([1, 2])
with col1:
    submit = st.button("é€ä¿¡", type="primary")
with col2:
    st.caption("â€» `.env` ã« OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

if submit:
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚")
    else:
        try:
            with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
                answer = ask_llm(user_text=user_text, expert_type=expert_type)
            st.subheader("å›ç­”")
            st.write(answer)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

